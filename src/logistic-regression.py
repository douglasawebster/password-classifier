import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Really good article https://realpython.com/logistic-regression-python/

x = np.array([
[0.0,39.32753311006582,0.06382978723404255,0.0,26],
[2.6390158215457884,65.54588851677637,0.10638297872340426,0.0,18],
[11.825697551124144,52.436710813421094,0.0851063829787234,0.0,68],
[14.227676842568052,65.54588851677637,0.0851063829787234,0.3,98],
[0.0,52.436710813421094,0.05319148936170213,0.875,58],
[0.0,45.88212196174346,0.05319148936170213,0.42857142857142855,44],
[0.0,52.436710813421094,0.07446808510638298,0.125,62],
[7.917047464637365,65.54588851677637,0.0851063829787234,0.3,98],
[0.0,52.436710813421094,0.07446808510638298,0.125,62],
[0.0,39.32753311006582,0.031914893617021274,1.1666666666666667,22],
[0.0,45.88212196174346,0.05319148936170213,0.42857142857142855,50],
[0.0,52.436710813421094,0.0851063829787234,0.0,24],
[0.0,52.436710813421094,0.07446808510638298,0.125,26],
[0.0,52.436710813421094,0.07446808510638298,0.125,16],
[2.8284271247461903,52.436710813421094,0.0851063829787234,0.0,64],
[-999.0,45.88212196174346,0.07446808510638298,0.0,50],
[0.0,26.218355406710547,0.031914893617021274,0.25,20],
[0.0,98.31883277516455,0.031914893617021274,273.0,36],
[5.656854249492381,52.436710813421094,0.0425531914893617,1.875,54],
[0.0,58.99129966509873,0.09574468085106383,0.0,30],
[0.0,98.31883277516455,0.1276595744680851,0.4666666666666667,140],
[0.0,78.65506622013164,0.1276595744680851,0.0,100],
[5.189521808129815,78.65506622013164,0.11702127659574468,0.08333333333333333,108],
[10.109276159001974,117.98259933019746,0.1702127659574468,0.16666666666666666,152],
[0.0,131.09177703355275,0.19148936170212766,0.15,156],
[0.0,98.31883277516455,0.1595744680851064,0.0,136],
[0.0,72.10047736845401,0.11702127659574468,0.0,46],
[0.0,104.87342162684219,0.13829787234042554,0.4375,136],
[2.573329796018864,72.10047736845401,0.11702127659574468,0.0,70],
[2.721580000348754,58.99129966509873,0.09574468085106383,0.0,86],
[0.0,78.65506622013164,0.11702127659574468,0.08333333333333333,96],
[0.0,39.32753311006582,0.06382978723404255,0.0,38],
[8.106458767837767,65.54588851677637,0.09574468085106383,0.1,50],
[0.0,45.88212196174346,0.07446808510638298,0.0,38],
[5.670448954566584,65.54588851677637,0.10638297872340426,0.0,72],
[0.0,32.772944258388186,0.05319148936170213,0.0,54],
[0.0,39.32753311006582,0.05319148936170213,0.16666666666666666,26],
[0.0,45.88212196174346,0.06382978723404255,0.14285714285714285,32],
[2.721580000348754,58.99129966509873,0.06382978723404255,0.7777777777777778,16],
[4.999800687937496,91.76424392348692,0.11702127659574468,0.5,116],
])

y = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])

test_x = np.array([
[0.0,104.87342162684219,0.010638297872340425,2047.9375,0],
[0.0,104.87342162684219,0.02127659574468085,1023.9375,10],
[0.0,104.87342162684219,0.031914893617021274,511.9375,14],
[0.0,104.87342162684219,0.0425531914893617,255.9375,16],
[0.0,104.87342162684219,0.0851063829787234,15.9375,26],
[17.97767157670296,91.76424392348692,0.10638297872340426,1.0714285714285714,98],
[8.094881557901331,91.76424392348692,0.1276595744680851,0.21428571428571427,84],
[-999.0,45.88212196174346,0.07446808510638298,0.0,50],
[0.0,58.99129966509873,0.09574468085106383,0.0,16],
[0.0,26.218355406710547,0.0425531914893617,0.0,6],
[2.721580000348754,58.99129966509873,0.09574468085106383,0.0,22],
[0.0,58.99129966509873,0.09574468085106383,0.0,16],
[8.295870071038168,65.54588851677637,0.07446808510638298,0.7,86],
[0.0,52.436710813421094,0.0851063829787234,0.0,34],
[0.0,65.54588851677637,0.05319148936170213,3.1,22],
[0.0,85.20965507180928,0.13829787234042554,0.0,62],
[2.475452570610856,85.20965507180928,0.11702127659574468,0.23076923076923078,78],
[0.0,65.54588851677637,0.09574468085106383,0.1,70],
[7.934222674460249,98.31883277516455,0.13829787234042554,0.2,98],
[0.0,78.65506622013164,0.10638297872340426,0.25,110],
[0.0,98.31883277516455,0.13829787234042554,0.2,134],
[0.0,78.65506622013164,0.1276595744680851,0.0,78],
[0.0,85.20965507180928,0.13829787234042554,0.0,102],
[0.0,65.54588851677637,0.10638297872340426,0.0,64],
[0.0,65.54588851677637,0.09574468085106383,0.1,66],
[0.0,65.54588851677637,0.10638297872340426,0.0,118],
[0.0,65.54588851677637,0.09574468085106383,0.1,78],
[0.0,65.54588851677637,0.10638297872340426,0.0,108],
[0.0,65.54588851677637,0.0851063829787234,0.3,102],
[0.0,52.436710813421094,0.07446808510638298,0.125,78],
[0.0,52.436710813421094,0.0851063829787234,0.0,80],
[0.0,52.436710813421094,0.07446808510638298,0.125,54],
[0.0,85.20965507180928,0.13829787234042554,0.0,122],
[0.0,85.20965507180928,0.1276595744680851,0.07692307692307693,110],
[0.0,85.20965507180928,0.1276595744680851,0.07692307692307693,94],
])

test_y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])

model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)

#print(model.predict(x))
#print(model.score(x, y))

print(model.predict(test_x))
print(model.score(test_x, test_y))

cm = confusion_matrix(test_y, model.predict(test_x))
fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm)
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')
plt.show()

# print(classification_report(test_y, model.predict(test_x)))